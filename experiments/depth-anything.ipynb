{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mambaforge/envs/calhacks/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import depth_pro\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm  # For progress bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(image, transform, model, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Process a single frame to compute the depth and generate a heatmap.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): The input image frame in BGR format.\n",
    "        transform (callable): The preprocessing transform.\n",
    "        model (torch.nn.Module): The depth inference model.\n",
    "        device (str): Device to perform computation on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The heatmap image in BGR format.\n",
    "    \"\"\"\n",
    "    # Convert BGR (OpenCV) to RGB (PIL)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(image_rgb)\n",
    "\n",
    "    # Preprocess the image\n",
    "    transformed_image = transform(pil_image).unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        prediction = model.infer(transformed_image, f_px=None)  # Modify if f_px is required\n",
    "\n",
    "    depth = prediction[\"depth\"].squeeze().cpu().numpy()  # Remove batch dimension and convert to numpy\n",
    "\n",
    "    # Normalize depth for visualization\n",
    "    depth_normalized = cv2.normalize(depth, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    depth_uint8 = depth_normalized.astype(np.uint8)\n",
    "\n",
    "    # Apply a colormap to create a heatmap\n",
    "    heatmap = cv2.applyColorMap(depth_uint8, cv2.COLORMAP_JET)\n",
    "\n",
    "    return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(input_video_path, output_video_path, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Process the input video to generate a heatmap video based on depth information.\n",
    "\n",
    "    Args:\n",
    "        input_video_path (str): Path to the input video file.\n",
    "        output_video_path (str): Path to save the output heatmap video.\n",
    "        device (str): Device to perform computation on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Record the start time for model loading\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Load model and preprocessing transform\n",
    "    model, transform = depth_pro.create_model_and_transforms(device=device)\n",
    "    model.eval()\n",
    "\n",
    "    # Calculate and print the model loading time\n",
    "    model_load_time = time.time() - start_time\n",
    "    print(f\"Model loading time: {model_load_time:.2f} seconds\")\n",
    "\n",
    "    # Initialize video capture\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open video {input_video_path}\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can choose other codecs\n",
    "\n",
    "    # Initialize video writer\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Processing {frame_count} frames...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    processed_frames = 0\n",
    "\n",
    "    # Use tqdm for progress bar\n",
    "    for _ in tqdm(range(frame_count), desc=\"Processing Frames\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # End of video\n",
    "\n",
    "        heatmap = process_frame(frame, transform, model, device=device)\n",
    "\n",
    "        # Write the heatmap frame to the output video\n",
    "        out.write(heatmap)\n",
    "\n",
    "        processed_frames += 1\n",
    "\n",
    "    # Calculate and print the total processing time\n",
    "    total_time = time.time() - start_time\n",
    "    fps_processed = processed_frames / total_time if total_time > 0 else 0\n",
    "    print(f\"Processed {processed_frames} frames in {total_time:.2f} seconds ({fps_processed:.2f} FPS)\")\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Heatmap video saved to {output_video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/calhacks24/experiments/ml-depth-pro/src/depth_pro/depth_pro.py:135: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(config.checkpoint_uri, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loading time: 14.76 seconds\n",
      "Processing 227 frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Frames: 100%|██████████| 227/227 [01:34<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 227 frames in 94.47 seconds (2.40 FPS)\n",
      "Heatmap video saved to flood_heat.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define input and output video paths\n",
    "input_video_path = \"flood.mp4\"      # Replace with your input video path\n",
    "output_video_path = \"flood_heat.mp4\" # Replace with your desired output path\n",
    "\n",
    "# Check if input video exists\n",
    "if not os.path.isfile(input_video_path):\n",
    "    print(f\"Input video file {input_video_path} does not exist. Please provide a valid path.\")\n",
    "else:\n",
    "    # Choose device: 'cuda' if available, else 'cpu'\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Process the video to generate heatmap\n",
    "    process_video(input_video_path, output_video_path, device=device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calhacks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

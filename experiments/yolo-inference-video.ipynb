{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection on Video using YOLOv8\n",
    "\n",
    "This notebook demonstrates how to perform object detection on a video using the Ultralytics YOLOv8 model. The script processes each frame of the input video, draws bounding boxes around detected objects, and saves the annotated frames into an output video file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Import necessary libraries\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Define the YoloInference class for handling model predictions\n",
    "class YoloInference:\n",
    "    def __init__(self, model_path: str = \"yolov8n.pt\") -> None:\n",
    "        \"\"\"\n",
    "        Initializes the YOLO model.\n",
    "        \n",
    "        Args:\n",
    "            model_path (str): Path to the YOLO model file.\n",
    "        \"\"\"\n",
    "        self.model = YOLO(model_path)\n",
    "    \n",
    "    def predict(self, frame, conf_threshold=0.25, iou_threshold=0.45):\n",
    "        \"\"\"\n",
    "        Performs object detection on a single frame.\n",
    "        \n",
    "        Args:\n",
    "            frame (numpy.ndarray): The input frame in BGR format.\n",
    "            conf_threshold (float): Confidence threshold for detections.\n",
    "            iou_threshold (float): IoU threshold for Non-Max Suppression.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: The frame with bounding boxes drawn.\n",
    "        \"\"\"\n",
    "        # Convert frame from BGR to RGB\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Perform prediction\n",
    "        results = self.model.predict(\n",
    "            source=img_rgb,\n",
    "            conf=conf_threshold,\n",
    "            iou=iou_threshold,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Iterate through detections and draw bounding boxes\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                # Extract bounding box coordinates\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                conf = box.conf[0]\n",
    "                cls = box.cls[0]\n",
    "                label = f\"{self.model.names[int(cls)]} {conf:.2f}\"\n",
    "                \n",
    "                # Draw rectangle\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                \n",
    "                # Put label\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    label,\n",
    "                    (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (0, 255, 0),\n",
    "                    2\n",
    "                )\n",
    "        \n",
    "        return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Function to process video\n",
    "def process_video(input_path: str, output_path: str, model: YoloInference, conf_threshold: float = 0.25, iou_threshold: float = 0.45):\n",
    "    \"\"\"\n",
    "    Processes the input video, performs object detection on each frame, and saves the output video.\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to the input video file.\n",
    "        output_path (str): Path to save the output video file.\n",
    "        model (YoloInference): An instance of the YoloInference class.\n",
    "        conf_threshold (float): Confidence threshold for detections.\n",
    "        iou_threshold (float): IoU threshold for Non-Max Suppression.\n",
    "    \"\"\"\n",
    "    # Check if input video exists\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Error: Input video not found at {input_path}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Initialize video capture\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {input_path}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Get video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can choose other codecs\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Processing video: {input_path}\")\n",
    "    print(f\"Total frames: {frame_count}\")\n",
    "    \n",
    "    current_frame = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Perform inference and draw bounding boxes\n",
    "        annotated_frame = model.predict(frame, conf_threshold, iou_threshold)\n",
    "        \n",
    "        # Write the frame to the output video\n",
    "        out.write(annotated_frame)\n",
    "        \n",
    "        current_frame += 1\n",
    "        if current_frame % 10 == 0:\n",
    "            print(f\"Processed {current_frame}/{frame_count} frames\")\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Processing completed. Output saved at {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Initialize the YOLO model\n",
    "# You can choose a different model or provide a custom checkpoint\n",
    "model_path = \"checkpoints/yolo11s_NP.pt\"  # Replace with your model path if different\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"Error: YOLO model not found at {model_path}\")\n",
    "    print(\"Please download a YOLOv8 model from https://ultralytics.com/\")\n",
    "    sys.exit(1)\n",
    "\n",
    "yolo_inference = YoloInference(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: flood.mp4\n",
      "Total frames: 227\n",
      "Processed 10/227 frames\n",
      "Processed 20/227 frames\n",
      "Processed 30/227 frames\n",
      "Processed 40/227 frames\n",
      "Processed 50/227 frames\n",
      "Processed 60/227 frames\n",
      "Processed 70/227 frames\n",
      "Processed 80/227 frames\n",
      "Processed 90/227 frames\n",
      "Processed 100/227 frames\n",
      "Processed 110/227 frames\n",
      "Processed 120/227 frames\n",
      "Processed 130/227 frames\n",
      "Processed 140/227 frames\n",
      "Processed 150/227 frames\n",
      "Processed 160/227 frames\n",
      "Processed 170/227 frames\n",
      "Processed 180/227 frames\n",
      "Processed 190/227 frames\n",
      "Processed 200/227 frames\n",
      "Processed 210/227 frames\n",
      "Processed 220/227 frames\n",
      "Processing completed. Output saved at flood_boxes.mp4\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Define input and output video paths\n",
    "input_video_path = \"flood.mp4\"   # Replace with your input video path\n",
    "output_video_path = \"flood_boxes.mp4\"  # Desired output video path\n",
    "\n",
    "# Process the video\n",
    "process_video(\n",
    "    input_path=input_video_path,\n",
    "    output_path=output_video_path,\n",
    "    model=yolo_inference,\n",
    "    conf_threshold=0.4,  # Adjust as needed\n",
    "    iou_threshold=0.4    # Adjust as needed\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calhacks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
